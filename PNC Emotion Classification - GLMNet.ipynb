{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub shape: (759, 10)\n",
      "The first 3 columns are: Index(['Subj', 'Age', 'Sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/yuanzh/Google Drive/Files_PNC_Analysis'\n",
    "\n",
    "# load subject info\n",
    "filename = 'SubInfo_2018.txt'\n",
    "sub = pd.read_csv(os.path.join(path, filename), header=0, delimiter='\\t')\n",
    "print(\"sub shape: \" + str(sub.shape))\n",
    "print(\"The first 3 columns are: \" + str(sub.columns[0:3]))\n",
    "sub.head(3)\n",
    "\n",
    "num_sub = sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion condition (classes)\n",
    "emotion = ['fear','anger','sad','happy'] # this is a list\n",
    "#print(emotion)\n",
    "\n",
    "# load connectivity into dictionary conn\n",
    "path = '/Users/yuanzh/Google Drive/Files_PNC_Analysis'\n",
    "path = path +'/BS_Conn_50ROIs_2018/Original Data'\n",
    "#print(path)\n",
    "\n",
    "df = {} # save connectivity under Fear, Anger, Sad, and Happy\n",
    "\n",
    "for i in range(len(emotion)):\n",
    "    filename = 'bs_conns_' + emotion[i] + '.txt'  \n",
    "    #print(filename)\n",
    "    conn = pd.read_csv(os.path.join(path, filename), header=0, delimiter='\\t')\n",
    "    # check the shape\n",
    "    #print(conn.shape)\n",
    "    # get name of the last unused column\n",
    "    col = conn.columns[-1]\n",
    "    #print(\"last column: \" + str(col))\n",
    "    # drop the last unused column\n",
    "    conn = conn.drop(str(col),1)\n",
    "    # check the shape\n",
    "    #print(conn.shape)\n",
    "    df[str(emotion[i])] = pd.concat([sub, conn], axis=1) #concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fear', 'anger', 'sad', 'happy'])\n",
      "(759, 1236)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>GScore</th>\n",
       "      <th>GGroup</th>\n",
       "      <th>DScore</th>\n",
       "      <th>DGroup</th>\n",
       "      <th>Motion</th>\n",
       "      <th>Agebin</th>\n",
       "      <th>...</th>\n",
       "      <th>VLPFC.R_DLPFC.L</th>\n",
       "      <th>VLPFC.R_DLPFC.R</th>\n",
       "      <th>VLPFC.R_DLPFCm.L</th>\n",
       "      <th>VLPFC.R_DLPFCm.R</th>\n",
       "      <th>DLPFC.L_DLPFC.R</th>\n",
       "      <th>DLPFC.L_DLPFCm.L</th>\n",
       "      <th>DLPFC.L_DLPFCm.R</th>\n",
       "      <th>DLPFC.R_DLPFCm.L</th>\n",
       "      <th>DLPFC.R_DLPFCm.R</th>\n",
       "      <th>DLPFCm.L_DLPFCm.R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009963128</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149664</td>\n",
       "      <td>Children</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>1.2809</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>1.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600018902293</td>\n",
       "      <td>15.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.5669</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>1.1184</td>\n",
       "      <td>1.1773</td>\n",
       "      <td>1.0380</td>\n",
       "      <td>1.1589</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>1.2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600020364885</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056563</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.4853</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.6449</td>\n",
       "      <td>1.0761</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>-0.0811</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.9859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subj        Age  Sex  Race  GScore  GGroup  DScore  DGroup  \\\n",
       "0  600009963128   9.666667    0     0       0       0       0       0   \n",
       "1  600018902293  15.583333    0     0      12       1       4       1   \n",
       "2  600020364885  17.750000    1     0       2       1       0       0   \n",
       "\n",
       "     Motion       Agebin        ...          VLPFC.R_DLPFC.L  VLPFC.R_DLPFC.R  \\\n",
       "0  0.149664     Children        ...                   0.4722           0.9470   \n",
       "1  0.059930  Adolescents        ...                   0.3621           0.3730   \n",
       "2  0.056563  Adolescents        ...                   0.7979           0.4853   \n",
       "\n",
       "   VLPFC.R_DLPFCm.L  VLPFC.R_DLPFCm.R  DLPFC.L_DLPFC.R  DLPFC.L_DLPFCm.L  \\\n",
       "0            0.7317            1.2809           0.8010            0.0175   \n",
       "1            0.5669            0.5315           1.1184            1.1773   \n",
       "2            0.3248            0.6449           1.0761            0.0941   \n",
       "\n",
       "   DLPFC.L_DLPFCm.R  DLPFC.R_DLPFCm.L  DLPFC.R_DLPFCm.R  DLPFCm.L_DLPFCm.R  \n",
       "0            0.1136            0.2156            0.5137             1.2603  \n",
       "1            1.0380            1.1589            0.6858             1.2571  \n",
       "2            0.2069           -0.0811            0.1089             0.9859  \n",
       "\n",
       "[3 rows x 1236 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data check\n",
    "print(df.keys())\n",
    "print(df[str(emotion[0])].shape)\n",
    "df[str(emotion[0])].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 1236)\n"
     ]
    }
   ],
   "source": [
    "# combine four emotion data\n",
    "data = pd.concat([df[\"fear\"],df[\"anger\"],df[\"sad\"],df[\"happy\"]], axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with column mean\n",
    "def replace_nan(X):\n",
    "    col_mean = np.nanmean(X, axis=0) # obtain column means\n",
    "    ind = np.where(np.isnan(X)) # find the position of missing values\n",
    "    X[ind] = np.take(col_mean, ind[1]) # replace nans with colmeans\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3036, 1225)\ty shape: (3036,)\tG shape: (3036,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for emotion classification\n",
    "\n",
    "# Features\n",
    "X = data.drop(columns = sub.columns) # drop subID, age, group etc.\n",
    "#X.head(3)\n",
    "X = X.drop(columns = X.columns[0]) # drop subID\n",
    "#X.head(3)\n",
    "X = X.values # convert pandas dataframe to numpy array\n",
    "# print(X.shape)\n",
    "#print(type(X))\n",
    "X = replace_nan(X) # deal with missing values in numpy array\n",
    "\n",
    "# Labels\n",
    "y = np.array([1,2,3,4]) \n",
    "y = np.repeat(y, num_sub)\n",
    "\n",
    "# Groups\n",
    "# Group info that will be used to do train-test split\n",
    "# data belongs to the same subject should not be splited into different folds\n",
    "G = np.array(range(num_sub)) +1\n",
    "G = np.tile(G, 4).T\n",
    "#print(G[0,759:789])\n",
    "print('X shape: ' + str(X.shape) + '\\ty shape: ' + str(y.shape) + '\\tG shape: ' + str(G.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split for 10 fold cross validation; \n",
    "# samples that belong to the same subject will not be\n",
    "# split into different folds\n",
    "def get_cv(X, y, G):\n",
    "    cv = GroupShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 42)\n",
    "    nfold = cv.get_n_splits()\n",
    "    cv = cv.split(X, y, G)\n",
    "    \n",
    "    return cv, nfold\n",
    "\n",
    "# train_inds, test_inds = next(cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Example of subsetting numpy array\n",
    "a = np.arange(100).reshape(10,10)\n",
    "#print(a)\n",
    "n1, n2 = np.arange(5), np.arange(5)\n",
    "#print(n1.shape)\n",
    "b = a[n1[:,None],n2[None,:]]\n",
    "b\n",
    "\n",
    "n1 = np.concatenate((np.arange(100), np.arange(100)+759))\n",
    "n1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Test using glmnet\n",
    "import glmnet\n",
    "\n",
    "model = glmnet.logistic.LogitNet(alpha=0.2)\n",
    "\n",
    "inds = np.concatenate((np.arange(100), np.arange(100)+759, np.arange(100)+759*2, np.arange(100)+759*3))\n",
    "m = model.fit(X[inds,:],y[inds])\n",
    "\n",
    "m.predict(X[inds+100,:]) # this returns the predicted value at the best lambda\n",
    "np.sum(m.predict == y[inds+100])\n",
    "m.lambda_best_  # best lambda\n",
    "m.lambda_best_inx_  # the position of the best lambda\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,0,0,1,1,0,0,])\n",
    "b = np.array([0,1,0,1,0,1,0,1])\n",
    "\n",
    "c = []\n",
    "c = np.concatenate((c,a))\n",
    "c = np.concatenate((c, b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of folds: 10\n",
      "alpha 0.1\n",
      "fold 0\n",
      "training accuracy: 0.42174629324546953 at alpha: 0.1 and lambda: [0.13207011]\n",
      "test accuracy 0.3157894736842105 at alpha: 0.1 and lambda: [0.13207011]\n",
      "fold 1\n",
      "training accuracy: 0.39847611202635913 at alpha: 0.1 and lambda: [0.18459305]\n",
      "test accuracy 0.3207236842105263 at alpha: 0.1 and lambda: [0.18459305]\n",
      "fold 2\n",
      "training accuracy: 0.3938769906644701 at alpha: 0.1 and lambda: [0.17067644]\n",
      "test accuracy 0.3157894736842105 at alpha: 0.1 and lambda: [0.17067644]\n",
      "fold 3\n",
      "training accuracy: 0.3902388797364086 at alpha: 0.1 and lambda: [0.17758013]\n",
      "test accuracy 0.31085526315789475 at alpha: 0.1 and lambda: [0.17758013]\n",
      "fold 4\n",
      "training accuracy: 0.41046128500823725 at alpha: 0.1 and lambda: [0.06596863]\n",
      "test accuracy 0.31282894736842104 at alpha: 0.1 and lambda: [0.06596863]\n",
      "fold 5\n",
      "training accuracy: 0.40266337177375067 at alpha: 0.1 and lambda: [0.17651345]\n",
      "test accuracy 0.3149671052631579 at alpha: 0.1 and lambda: [0.17651345]\n",
      "fold 6\n",
      "training accuracy: 0.3997411155566016 at alpha: 0.1 and lambda: [0.16857516]\n",
      "test accuracy 0.31414473684210525 at alpha: 0.1 and lambda: [0.16857516]\n",
      "fold 7\n",
      "training accuracy: 0.40691927512355847 at alpha: 0.1 and lambda: [0.09325336]\n",
      "test accuracy 0.3118832236842105 at alpha: 0.1 and lambda: [0.09325336]\n",
      "fold 8\n",
      "training accuracy: 0.4075141863444994 at alpha: 0.1 and lambda: [0.12285138]\n",
      "test accuracy 0.3121345029239766 at alpha: 0.1 and lambda: [0.12285138]\n",
      "fold 9\n",
      "training accuracy: 0.40448929159802305 at alpha: 0.1 and lambda: [0.16884354]\n",
      "test accuracy 0.31282894736842104 at alpha: 0.1 and lambda: [0.16884354]\n",
      "training accuracy: 0.40448929159802305 at alpha: 0.1\n",
      "test accuracy 0.31282894736842104 at alpha: 0.1\n",
      "alpha 0.2\n",
      "fold 0\n",
      "training accuracy: 0.4049722929459338 at alpha: 0.2 and lambda: [0.07247339]\n",
      "test accuracy 0.31220095693779903 at alpha: 0.2 and lambda: [0.07247339]\n",
      "fold 1\n",
      "training accuracy: 0.4029722679846238 at alpha: 0.2 and lambda: [0.09229652]\n",
      "test accuracy 0.3129111842105263 at alpha: 0.2 and lambda: [0.09229652]\n",
      "fold 2\n",
      "training accuracy: 0.40267393232796855 at alpha: 0.2 and lambda: [0.07775701]\n",
      "test accuracy 0.3125 at alpha: 0.2 and lambda: [0.07775701]\n",
      "fold 3\n",
      "training accuracy: 0.4035655448340786 at alpha: 0.2 and lambda: [0.06716643]\n",
      "test accuracy 0.3117951127819549 at alpha: 0.2 and lambda: [0.06716643]\n",
      "fold 4\n",
      "training accuracy: 0.4085667215815486 at alpha: 0.2 and lambda: [0.03972973]\n",
      "test accuracy 0.3117324561403509 at alpha: 0.2 and lambda: [0.03972973]\n",
      "fold 5\n",
      "training accuracy: 0.40596684514003295 at alpha: 0.2 and lambda: [0.08825672]\n",
      "test accuracy 0.31229440789473684 at alpha: 0.2 and lambda: [0.08825672]\n",
      "fold 6\n",
      "training accuracy: 0.4053202829731563 at alpha: 0.2 and lambda: [0.0767997]\n",
      "test accuracy 0.3123065015479876 at alpha: 0.2 and lambda: [0.0767997]\n",
      "fold 7\n",
      "training accuracy: 0.4063014827018122 at alpha: 0.2 and lambda: [0.06764733]\n",
      "test accuracy 0.311312134502924 at alpha: 0.2 and lambda: [0.06764733]\n",
      "fold 8\n",
      "training accuracy: 0.40839330616491804 at alpha: 0.2 and lambda: [0.05099669]\n",
      "test accuracy 0.31068213296398894 at alpha: 0.2 and lambda: [0.05099669]\n",
      "fold 9\n",
      "training accuracy: 0.4057042833607908 at alpha: 0.2 and lambda: [0.10168632]\n",
      "test accuracy 0.30970394736842105 at alpha: 0.2 and lambda: [0.10168632]\n",
      "training accuracy: 0.4057042833607908 at alpha: 0.2\n",
      "test accuracy 0.30970394736842105 at alpha: 0.2\n",
      "alpha 0.30000000000000004\n",
      "fold 0\n",
      "training accuracy: 0.4060759394367302 at alpha: 0.30000000000000004 and lambda: [0.04831559]\n",
      "test accuracy 0.30968045112781956 at alpha: 0.30000000000000004 and lambda: [0.04831559]\n",
      "fold 1\n",
      "training accuracy: 0.40504717687584246 at alpha: 0.30000000000000004 and lambda: [0.06153102]\n",
      "test accuracy 0.3098833732057416 at alpha: 0.30000000000000004 and lambda: [0.06153102]\n",
      "fold 2\n",
      "training accuracy: 0.40428694219611777 at alpha: 0.30000000000000004 and lambda: [0.05689215]\n",
      "test accuracy 0.3100686498855835 at alpha: 0.30000000000000004 and lambda: [0.05689215]\n",
      "fold 3\n",
      "training accuracy: 0.4048256452498627 at alpha: 0.30000000000000004 and lambda: [0.04477762]\n",
      "test accuracy 0.3101014254385965 at alpha: 0.30000000000000004 and lambda: [0.04477762]\n",
      "fold 4\n",
      "training accuracy: 0.4068863261943987 at alpha: 0.30000000000000004 and lambda: [0.03190306]\n",
      "test accuracy 0.31026315789473685 at alpha: 0.30000000000000004 and lambda: [0.03190306]\n",
      "fold 5\n",
      "training accuracy: 0.40530351032822204 at alpha: 0.30000000000000004 and lambda: [0.05883782]\n",
      "test accuracy 0.3102226720647773 at alpha: 0.30000000000000004 and lambda: [0.05883782]\n",
      "fold 6\n",
      "training accuracy: 0.40492098358655193 at alpha: 0.30000000000000004 and lambda: [0.0511998]\n",
      "test accuracy 0.3102461013645224 at alpha: 0.30000000000000004 and lambda: [0.0511998]\n",
      "fold 7\n",
      "training accuracy: 0.40469816427394684 at alpha: 0.30000000000000004 and lambda: [0.05432097]\n",
      "test accuracy 0.30926926691729323 at alpha: 0.30000000000000004 and lambda: [0.05432097]\n",
      "fold 8\n",
      "training accuracy: 0.40538544566267115 at alpha: 0.30000000000000004 and lambda: [0.04095046]\n",
      "test accuracy 0.3092105263157895 at alpha: 0.30000000000000004 and lambda: [0.04095046]\n",
      "fold 9\n",
      "training accuracy: 0.4042009884678748 at alpha: 0.30000000000000004 and lambda: [0.06176852]\n",
      "test accuracy 0.3088267543859649 at alpha: 0.30000000000000004 and lambda: [0.06176852]\n",
      "training accuracy: 0.4042009884678748 at alpha: 0.30000000000000004\n",
      "test accuracy 0.3088267543859649 at alpha: 0.30000000000000004\n",
      "alpha 0.4\n",
      "fold 0\n",
      "training accuracy: 0.4045676781633629 at alpha: 0.4 and lambda: [0.0362367]\n",
      "test accuracy 0.3086799660441426 at alpha: 0.4 and lambda: [0.0362367]\n",
      "fold 1\n",
      "training accuracy: 0.403830313014827 at alpha: 0.4 and lambda: [0.04614826]\n",
      "test accuracy 0.3088507401315789 at alpha: 0.4 and lambda: [0.04614826]\n",
      "fold 2\n",
      "training accuracy: 0.40376166941241076 at alpha: 0.4 and lambda: [0.0388785]\n",
      "test accuracy 0.30881180223285487 at alpha: 0.4 and lambda: [0.0388785]\n",
      "fold 3\n",
      "training accuracy: 0.4026189553251284 at alpha: 0.4 and lambda: [0.04872349]\n",
      "test accuracy 0.3087751547987616 at alpha: 0.4 and lambda: [0.04872349]\n",
      "fold 4\n",
      "training accuracy: 0.4042009884678748 at alpha: 0.4 and lambda: [0.0239273]\n",
      "test accuracy 0.30911654135338346 at alpha: 0.4 and lambda: [0.0239273]\n",
      "fold 5\n",
      "training accuracy: 0.40315531759106715 at alpha: 0.4 and lambda: [0.04412836]\n",
      "test accuracy 0.30916483918128657 at alpha: 0.4 and lambda: [0.04412836]\n",
      "fold 6\n",
      "training accuracy: 0.4029787612983659 at alpha: 0.4 and lambda: [0.03839985]\n",
      "test accuracy 0.3090771692745377 at alpha: 0.4 and lambda: [0.03839985]\n",
      "fold 7\n",
      "training accuracy: 0.40376528223359054 at alpha: 0.4 and lambda: [0.03081886]\n",
      "test accuracy 0.3084314404432133 at alpha: 0.4 and lambda: [0.03081886]\n",
      "fold 8\n",
      "training accuracy: 0.4061061124487813 at alpha: 0.4 and lambda: [0.01928856]\n",
      "test accuracy 0.30870445344129555 at alpha: 0.4 and lambda: [0.01928856]\n",
      "fold 9\n",
      "training accuracy: 0.4048187808896211 at alpha: 0.4 and lambda: [0.05084316]\n",
      "test accuracy 0.30838815789473684 at alpha: 0.4 and lambda: [0.05084316]\n",
      "training accuracy: 0.4048187808896211 at alpha: 0.4\n",
      "test accuracy 0.30838815789473684 at alpha: 0.4\n",
      "alpha 0.5\n",
      "fold 0\n",
      "training accuracy: 0.4050709205609354 at alpha: 0.5 and lambda: [0.02898936]\n",
      "test accuracy 0.30832798459563543 at alpha: 0.5 and lambda: [0.02898936]\n",
      "fold 1\n",
      "training accuracy: 0.40451674903898954 at alpha: 0.5 and lambda: [0.03691861]\n",
      "test accuracy 0.30858395989974935 at alpha: 0.5 and lambda: [0.03691861]\n",
      "fold 2\n",
      "training accuracy: 0.4040937128845638 at alpha: 0.5 and lambda: [0.03413529]\n",
      "test accuracy 0.30871328029375766 at alpha: 0.5 and lambda: [0.03413529]\n",
      "fold 3\n",
      "training accuracy: 0.4031563576456492 at alpha: 0.5 and lambda: [0.0389788]\n",
      "test accuracy 0.3086872009569378 at alpha: 0.5 and lambda: [0.0389788]\n",
      "fold 4\n",
      "training accuracy: 0.4020410031118433 at alpha: 0.5 and lambda: [0.04422013]\n",
      "test accuracy 0.3086622807017544 at alpha: 0.5 and lambda: [0.04422013]\n",
      "fold 5\n",
      "training accuracy: 0.40101890982021343 at alpha: 0.5 and lambda: [0.03874466]\n",
      "test accuracy 0.3084954233409611 at alpha: 0.5 and lambda: [0.03874466]\n",
      "fold 6\n",
      "training accuracy: 0.40090784815450947 at alpha: 0.5 and lambda: [0.03071988]\n",
      "test accuracy 0.30833566629339304 at alpha: 0.5 and lambda: [0.03071988]\n",
      "fold 7\n",
      "training accuracy: 0.4015736545853926 at alpha: 0.5 and lambda: [0.02465509]\n",
      "test accuracy 0.3078741776315789 at alpha: 0.5 and lambda: [0.02465509]\n",
      "fold 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.40207779981844466 at alpha: 0.5 and lambda: [0.02457028]\n",
      "test accuracy 0.30796858216971 at alpha: 0.5 and lambda: [0.02457028]\n",
      "fold 9\n",
      "training accuracy: 0.40454695222405274 at alpha: 0.5 and lambda: [0.01213584]\n",
      "test accuracy 0.30838815789473684 at alpha: 0.5 and lambda: [0.01213584]\n",
      "training accuracy: 0.40454695222405274 at alpha: 0.5\n",
      "test accuracy 0.30838815789473684 at alpha: 0.5\n",
      "alpha 0.6000000000000001\n",
      "fold 0\n",
      "training accuracy: 0.404738831282101 at alpha: 0.6000000000000001 and lambda: [0.0241578]\n",
      "test accuracy 0.30837203302373584 at alpha: 0.6000000000000001 and lambda: [0.0241578]\n",
      "fold 1\n",
      "training accuracy: 0.4042817767076416 at alpha: 0.6000000000000001 and lambda: [0.03076551]\n",
      "test accuracy 0.3085463056680162 at alpha: 0.6000000000000001 and lambda: [0.03076551]\n",
      "fold 2\n",
      "training accuracy: 0.40339125299182493 at alpha: 0.6000000000000001 and lambda: [0.0342634]\n",
      "test accuracy 0.30821747765640517 at alpha: 0.6000000000000001 and lambda: [0.0342634]\n",
      "fold 3\n",
      "training accuracy: 0.403883702483373 at alpha: 0.6000000000000001 and lambda: [0.02039985]\n",
      "test accuracy 0.3081749512670565 at alpha: 0.6000000000000001 and lambda: [0.02039985]\n",
      "fold 4\n",
      "training accuracy: 0.4046802456192901 at alpha: 0.6000000000000001 and lambda: [0.01750679]\n",
      "test accuracy 0.3085825358851675 at alpha: 0.6000000000000001 and lambda: [0.01750679]\n",
      "fold 5\n",
      "training accuracy: 0.40376412096963993 at alpha: 0.6000000000000001 and lambda: [0.03228722]\n",
      "test accuracy 0.30841752819548873 at alpha: 0.6000000000000001 and lambda: [0.03228722]\n",
      "fold 6\n",
      "training accuracy: 0.40350877192982454 at alpha: 0.6000000000000001 and lambda: [0.02809586]\n",
      "test accuracy 0.308373730378578 at alpha: 0.6000000000000001 and lambda: [0.02809586]\n",
      "fold 7\n",
      "training accuracy: 0.40443390331193546 at alpha: 0.6000000000000001 and lambda: [0.01705758]\n",
      "test accuracy 0.3080195099818512 at alpha: 0.6000000000000001 and lambda: [0.01705758]\n",
      "fold 8\n",
      "training accuracy: 0.40429452991930304 at alpha: 0.6000000000000001 and lambda: [0.02466249]\n",
      "test accuracy 0.3082627118644068 at alpha: 0.6000000000000001 and lambda: [0.02466249]\n",
      "fold 9\n",
      "training accuracy: 0.40396760021965955 at alpha: 0.6000000000000001 and lambda: [0.02564066]\n",
      "test accuracy 0.30855263157894736 at alpha: 0.6000000000000001 and lambda: [0.02564066]\n",
      "training accuracy: 0.40396760021965955 at alpha: 0.6000000000000001\n",
      "test accuracy 0.30855263157894736 at alpha: 0.6000000000000001\n",
      "alpha 0.7000000000000001\n",
      "fold 0\n",
      "training accuracy: 0.404124017608772 at alpha: 0.7000000000000001 and lambda: [0.02070668]\n",
      "test accuracy 0.30853645383951683 at alpha: 0.7000000000000001 and lambda: [0.02070668]\n",
      "fold 1\n",
      "training accuracy: 0.4037771695806983 at alpha: 0.7000000000000001 and lambda: [0.02637044]\n",
      "test accuracy 0.3087330220713073 at alpha: 0.7000000000000001 and lambda: [0.02637044]\n",
      "fold 2\n",
      "training accuracy: 0.4031732956774143 at alpha: 0.7000000000000001 and lambda: [0.0267596]\n",
      "test accuracy 0.30871449456975775 at alpha: 0.7000000000000001 and lambda: [0.0267596]\n",
      "fold 3\n",
      "training accuracy: 0.40236305601317957 at alpha: 0.7000000000000001 and lambda: [0.03055656]\n",
      "test accuracy 0.30879934210526316 at alpha: 0.7000000000000001 and lambda: [0.03055656]\n",
      "fold 4\n",
      "training accuracy: 0.40303510328222025 at alpha: 0.7000000000000001 and lambda: [0.01500582]\n",
      "test accuracy 0.3092105263157895 at alpha: 0.7000000000000001 and lambda: [0.01500582]\n",
      "fold 5\n",
      "training accuracy: 0.4020767809894663 at alpha: 0.7000000000000001 and lambda: [0.03037301]\n",
      "test accuracy 0.30898624401913877 at alpha: 0.7000000000000001 and lambda: [0.03037301]\n",
      "fold 6\n",
      "training accuracy: 0.4018785807371708 at alpha: 0.7000000000000001 and lambda: [0.02408217]\n",
      "test accuracy 0.3089650432050275 at alpha: 0.7000000000000001 and lambda: [0.02408217]\n",
      "fold 7\n",
      "training accuracy: 0.4023645702102917 at alpha: 0.7000000000000001 and lambda: [0.01761078]\n",
      "test accuracy 0.30867840557275544 at alpha: 0.7000000000000001 and lambda: [0.01761078]\n",
      "fold 8\n",
      "training accuracy: 0.4022753861948762 at alpha: 0.7000000000000001 and lambda: [0.02113927]\n",
      "test accuracy 0.30885297482837526 at alpha: 0.7000000000000001 and lambda: [0.02113927]\n",
      "fold 9\n",
      "training accuracy: 0.40387738291362674 at alpha: 0.7000000000000001 and lambda: [0.00951362]\n",
      "test accuracy 0.30904605263157897 at alpha: 0.7000000000000001 and lambda: [0.00951362]\n",
      "training accuracy: 0.40387738291362674 at alpha: 0.7000000000000001\n",
      "test accuracy 0.30904605263157897 at alpha: 0.7000000000000001\n",
      "alpha 0.8\n",
      "fold 0\n",
      "training accuracy: 0.40400723948302664 at alpha: 0.8 and lambda: [0.01811835]\n",
      "test accuracy 0.30902520385470716 at alpha: 0.8 and lambda: [0.01811835]\n",
      "fold 1\n",
      "training accuracy: 0.40367586490939045 at alpha: 0.8 and lambda: [0.02307413]\n",
      "test accuracy 0.30916483918128657 at alpha: 0.8 and lambda: [0.02307413]\n",
      "fold 2\n",
      "training accuracy: 0.4031673850736837 at alpha: 0.8 and lambda: [0.02341465]\n",
      "test accuracy 0.3090978731074261 at alpha: 0.8 and lambda: [0.02341465]\n",
      "fold 3\n",
      "training accuracy: 0.4033683601228906 at alpha: 0.8 and lambda: [0.01679161]\n",
      "test accuracy 0.30905494310099574 at alpha: 0.8 and lambda: [0.01679161]\n",
      "fold 4\n",
      "training accuracy: 0.40393190554640307 at alpha: 0.8 and lambda: [0.01313009]\n",
      "test accuracy 0.3093859649122807 at alpha: 0.8 and lambda: [0.01313009]\n",
      "fold 5\n",
      "training accuracy: 0.40307703979883813 at alpha: 0.8 and lambda: [0.02657638]\n",
      "test accuracy 0.30918888504155123 at alpha: 0.8 and lambda: [0.02657638]\n",
      "fold 6\n",
      "training accuracy: 0.4029022871691735 at alpha: 0.8 and lambda: [0.02107189]\n",
      "test accuracy 0.3091891660970608 at alpha: 0.8 and lambda: [0.02107189]\n",
      "fold 7\n",
      "training accuracy: 0.40330228530393275 at alpha: 0.8 and lambda: [0.01540943]\n",
      "test accuracy 0.30902074898785425 at alpha: 0.8 and lambda: [0.01540943]\n",
      "fold 8\n",
      "training accuracy: 0.40322294746939713 at alpha: 0.8 and lambda: [0.01849686]\n",
      "test accuracy 0.3091688874083944 at alpha: 0.8 and lambda: [0.01849686]\n",
      "fold 9\n",
      "training accuracy: 0.4046179983525535 at alpha: 0.8 and lambda: [0.00832442]\n",
      "test accuracy 0.3093133223684211 at alpha: 0.8 and lambda: [0.00832442]\n",
      "training accuracy: 0.4046179983525535 at alpha: 0.8\n",
      "test accuracy 0.3093133223684211 at alpha: 0.8\n",
      "alpha 0.9\n",
      "fold 0\n",
      "training accuracy: 0.40477352695913926 at alpha: 0.9 and lambda: [0.01467446]\n",
      "test accuracy 0.30931205328135153 at alpha: 0.9 and lambda: [0.01467446]\n",
      "fold 1\n",
      "training accuracy: 0.4044681962470366 at alpha: 0.9 and lambda: [0.02051034]\n",
      "test accuracy 0.30943116174582797 at alpha: 0.9 and lambda: [0.02051034]\n",
      "fold 2\n",
      "training accuracy: 0.4037583612869931 at alpha: 0.9 and lambda: [0.02506936]\n",
      "test accuracy 0.30926997463538364 at alpha: 0.9 and lambda: [0.02506936]\n",
      "fold 3\n",
      "training accuracy: 0.4039185690750765 at alpha: 0.9 and lambda: [0.01492587]\n",
      "test accuracy 0.30919094611528825 at alpha: 0.9 and lambda: [0.01492587]\n",
      "fold 4\n",
      "training accuracy: 0.40441418742126173 at alpha: 0.9 and lambda: [0.01167119]\n",
      "test accuracy 0.30950077399380804 at alpha: 0.9 and lambda: [0.01167119]\n",
      "fold 5\n",
      "training accuracy: 0.40382552392628634 at alpha: 0.9 and lambda: [0.02152481]\n",
      "test accuracy 0.30934440024479803 at alpha: 0.9 and lambda: [0.02152481]\n",
      "fold 6\n",
      "training accuracy: 0.40366225453994586 at alpha: 0.9 and lambda: [0.01873057]\n",
      "test accuracy 0.30934286146400486 at alpha: 0.9 and lambda: [0.01873057]\n",
      "fold 7\n",
      "training accuracy: 0.404265575857421 at alpha: 0.9 and lambda: [0.01137172]\n",
      "test accuracy 0.309061004784689 at alpha: 0.9 and lambda: [0.01137172]\n",
      "fold 8\n",
      "training accuracy: 0.40417970123836144 at alpha: 0.9 and lambda: [0.01644166]\n",
      "test accuracy 0.3091920461265523 at alpha: 0.9 and lambda: [0.01644166]\n",
      "fold 9\n",
      "training accuracy: 0.4054228445908841 at alpha: 0.9 and lambda: [0.00739949]\n",
      "test accuracy 0.30933845029239765 at alpha: 0.9 and lambda: [0.00739949]\n",
      "training accuracy: 0.4054228445908841 at alpha: 0.9\n",
      "test accuracy 0.30933845029239765 at alpha: 0.9\n",
      "alpha 1.0\n",
      "fold 0\n",
      "training accuracy: 0.40552075601498994 at alpha: 1.0 and lambda: [0.01449468]\n",
      "test accuracy 0.3092828224407172 at alpha: 1.0 and lambda: [0.01449468]\n",
      "fold 1\n",
      "training accuracy: 0.4054016546092687 at alpha: 1.0 and lambda: [0.01681943]\n",
      "test accuracy 0.30938930205949655 at alpha: 1.0 and lambda: [0.01681943]\n",
      "fold 2\n",
      "training accuracy: 0.4047492515633027 at alpha: 1.0 and lambda: [0.02256242]\n",
      "test accuracy 0.30924589700056593 at alpha: 1.0 and lambda: [0.02256242]\n",
      "fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.4048862560902941 at alpha: 1.0 and lambda: [0.01343329]\n",
      "test accuracy 0.3091580347144457 at alpha: 1.0 and lambda: [0.01343329]\n",
      "fold 4\n",
      "training accuracy: 0.4056143241134137 at alpha: 1.0 and lambda: [0.00872067]\n",
      "test accuracy 0.3092797783933518 at alpha: 1.0 and lambda: [0.00872067]\n",
      "fold 5\n",
      "training accuracy: 0.4050701880834706 at alpha: 1.0 and lambda: [0.01937233]\n",
      "test accuracy 0.3091419956140351 at alpha: 1.0 and lambda: [0.01937233]\n",
      "fold 6\n",
      "training accuracy: 0.40491091900337983 at alpha: 1.0 and lambda: [0.01685752]\n",
      "test accuracy 0.3091257460661964 at alpha: 1.0 and lambda: [0.01685752]\n",
      "fold 7\n",
      "training accuracy: 0.4053516793867465 at alpha: 1.0 and lambda: [0.0112324]\n",
      "test accuracy 0.3090426960257787 at alpha: 1.0 and lambda: [0.0112324]\n",
      "fold 8\n",
      "training accuracy: 0.4052593480105836 at alpha: 1.0 and lambda: [0.01479749]\n",
      "test accuracy 0.30912745879851145 at alpha: 1.0 and lambda: [0.01479749]\n",
      "fold 9\n",
      "training accuracy: 0.4061079077429984 at alpha: 1.0 and lambda: [0.00802144]\n",
      "test accuracy 0.3092927631578947 at alpha: 1.0 and lambda: [0.00802144]\n",
      "training accuracy: 0.4061079077429984 at alpha: 1.0\n",
      "test accuracy 0.3092927631578947 at alpha: 1.0\n"
     ]
    }
   ],
   "source": [
    "import glmnet\n",
    "\n",
    "alpha_range = (np.arange(10)+1)*0.1\n",
    "results = []\n",
    "\n",
    "cv_splits, nfold = get_cv(X, y, G)\n",
    "print(\"number of folds: \" + str(nfold))\n",
    "# get train and test indices for all folds\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "\n",
    "for train_inds, test_inds in cv_splits:\n",
    "    train_folds.append(train_inds)\n",
    "    test_folds.append(test_inds)\n",
    "\n",
    "\n",
    "    \n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    print(\"alpha \" + str(alpha))\n",
    "    \n",
    "    # nfold cross validation\n",
    "    for fd in range(nfold):\n",
    "    #for train_inds, test_inds in cv_splits:\n",
    "        print(\"fold \" + str(fd))\n",
    "        X_train, y_train, X_test, y_test = X[train_folds[fd],:], y[train_folds[fd]], X[test_folds[fd],:], y[test_folds[fd]]\n",
    "        \n",
    "        model = glmnet.logistic.LogitNet(alpha=alpha)\n",
    "        m = model.fit(X_train,y_train)\n",
    "        train_preds = np.concatenate((train_preds, m.predict(X_train) == y_train))\n",
    "        test_preds = np.concatenate((test_preds, m.predict(X_test) == y_test))\n",
    "        results.append((alpha, m.lambda_best_, train_preds, test_preds, m)) \n",
    "        print(\"training accuracy: \" + str(np.mean(train_preds)) + \" at alpha: \" + str(alpha) + \" and lambda: \" + str(m.lambda_best_))\n",
    "        print(\"test accuracy \" + str(np.mean(test_preds)) + \" at alpha: \" + str(alpha) + \" and lambda: \" + str(m.lambda_best_)) \n",
    "        fd += 1\n",
    "    \n",
    "    train_acc = np.mean(train_preds)\n",
    "    test_acc = np.mean(test_preds)\n",
    "    print(\"training accuracy: \" + str(train_acc) + \" at alpha: \" + str(alpha))\n",
    "    print(\"test accuracy \" + str(test_acc) + \" at alpha: \" + str(alpha))  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import glmnet\n",
    "# define my glmnet model (data normalization, glmnet)\n",
    "def myGLMNet(alpha):\n",
    "    pipe = Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"glmnet\", glmnet.logistic.LogitNet(alpha = alpha).fit())\n",
    "    ])\n",
    "\n",
    "# define evaluation\n",
    "def evaluation(X, y, G, alpha):\n",
    "    pipe = myGLMNet(alpha=alpha) \n",
    "    cv = get_cv(X, y, G)\n",
    "        \n",
    "    results = cross_validate(pipe, X, y, scoring=['accuracy'], cv=cv, verbose=1, return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "alpha_range = [0.1,0.5] #np.logspace(-7, 1, 9)\n",
    "models = []\n",
    "for alpha in alpha_range:\n",
    "        results = evaluation(X,y,G,alpha)\n",
    "        models.append((alpha,results))\n",
    "        print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),np.std(results['train_accuracy'])))\n",
    "        print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),np.std(results['test_accuracy'])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# define my SVC model (data normalization, SVC)\n",
    "def mySVC(gamma, C):\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", gamma=gamma, C=C))\n",
    "    ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mySVC(gamma=1, C=0.1)\n",
    "# model.fit(X_train,y_train)\n",
    "# model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def evaluation(X, y, G, gamma, C):\n",
    "    pipe = mySVC(gamma=gamma, C=C) \n",
    "    cv = get_cv(X, y, G)\n",
    "    #print(\"type(cv) = {}\".format(type(cv)))\n",
    "    \n",
    "    results = cross_validate(pipe, X, y, scoring=['accuracy'], cv=cv, verbose=1, return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    return results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = evaluation(X,y,G,gamma=1,C=0.1)\n",
    "#print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "#                                                         np.std(results['train_accuracy'])))\n",
    "#print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "#                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "C_range = np.exp2(np.array(range(-5,5))) #np.logspace(-3, 2, 6)\n",
    "gamma_range = np.exp2(np.array(range(-10,1)))\n",
    "models = []\n",
    "for C in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        results = evaluation(X,y,G,gamma,C)\n",
    "        models.append((C,gamma,results))\n",
    "        print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "        print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set the parameters\n",
    "#tuned_parameters = [{'kernal': ['rbf'], 'gamma':[np.exp2(np.array(range(-2,2)))], 'C': [np.exp2(np.array(range(-2,2)))]}]\n",
    "\n",
    "estimators = [(\"std_scaler\", StandardScaler()), (\"svc\", SVC())]\n",
    "tuned_parameters = [{'svc__gamma':[np.exp2(np.array(range(-2,2)))], 'svc__C': [np.exp2(np.array(range(-2,2)))]}]\n",
    "\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "#cv = get_cv(X, y, G)\n",
    "clf = GridSearchCV(pipe, param_grid = tuned_parameters, cv = 4, scoring='accuracy', n_jobs=-1)\n",
    "clf.fit(X,y)\n",
    "\n",
    "print('Best parameters set found: ')\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
