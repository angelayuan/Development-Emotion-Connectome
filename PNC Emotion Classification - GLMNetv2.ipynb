{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub shape: (759, 10)\n",
      "The first 3 columns are: Index(['Subj', 'Age', 'Sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/yuanzh/Google Drive/Files_PNC_Analysis'\n",
    "\n",
    "# load subject info\n",
    "filename = 'SubInfo_2018.txt'\n",
    "sub = pd.read_csv(os.path.join(path, filename), header=0, delimiter='\\t')\n",
    "print(\"sub shape: \" + str(sub.shape))\n",
    "print(\"The first 3 columns are: \" + str(sub.columns[0:3]))\n",
    "sub.head(3)\n",
    "\n",
    "num_sub = sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion condition (classes)\n",
    "emotion = ['fear','anger','sad','happy'] # this is a list\n",
    "#print(emotion)\n",
    "\n",
    "# load connectivity into dictionary conn\n",
    "path = '/Users/yuanzh/Google Drive/Files_PNC_Analysis'\n",
    "path = path +'/BS_Conn_50ROIs_2018/Original Data'\n",
    "#print(path)\n",
    "\n",
    "df = {} # save connectivity under Fear, Anger, Sad, and Happy\n",
    "\n",
    "for i in range(len(emotion)):\n",
    "    filename = 'bs_conns_' + emotion[i] + '.txt'  \n",
    "    #print(filename)\n",
    "    conn = pd.read_csv(os.path.join(path, filename), header=0, delimiter='\\t')\n",
    "    # check the shape\n",
    "    #print(conn.shape)\n",
    "    # get name of the last unused column\n",
    "    col = conn.columns[-1]\n",
    "    #print(\"last column: \" + str(col))\n",
    "    # drop the last unused column\n",
    "    conn = conn.drop(str(col),1)\n",
    "    # check the shape\n",
    "    #print(conn.shape)\n",
    "    df[str(emotion[i])] = pd.concat([sub, conn], axis=1) #concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fear', 'anger', 'sad', 'happy'])\n",
      "(759, 1236)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>GScore</th>\n",
       "      <th>GGroup</th>\n",
       "      <th>DScore</th>\n",
       "      <th>DGroup</th>\n",
       "      <th>Motion</th>\n",
       "      <th>Agebin</th>\n",
       "      <th>...</th>\n",
       "      <th>VLPFC.R_DLPFC.L</th>\n",
       "      <th>VLPFC.R_DLPFC.R</th>\n",
       "      <th>VLPFC.R_DLPFCm.L</th>\n",
       "      <th>VLPFC.R_DLPFCm.R</th>\n",
       "      <th>DLPFC.L_DLPFC.R</th>\n",
       "      <th>DLPFC.L_DLPFCm.L</th>\n",
       "      <th>DLPFC.L_DLPFCm.R</th>\n",
       "      <th>DLPFC.R_DLPFCm.L</th>\n",
       "      <th>DLPFC.R_DLPFCm.R</th>\n",
       "      <th>DLPFCm.L_DLPFCm.R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009963128</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149664</td>\n",
       "      <td>Children</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>1.2809</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>1.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600018902293</td>\n",
       "      <td>15.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.5669</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>1.1184</td>\n",
       "      <td>1.1773</td>\n",
       "      <td>1.0380</td>\n",
       "      <td>1.1589</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>1.2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600020364885</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056563</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.4853</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.6449</td>\n",
       "      <td>1.0761</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>-0.0811</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.9859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subj        Age  Sex  Race  GScore  GGroup  DScore  DGroup  \\\n",
       "0  600009963128   9.666667    0     0       0       0       0       0   \n",
       "1  600018902293  15.583333    0     0      12       1       4       1   \n",
       "2  600020364885  17.750000    1     0       2       1       0       0   \n",
       "\n",
       "     Motion       Agebin        ...          VLPFC.R_DLPFC.L  VLPFC.R_DLPFC.R  \\\n",
       "0  0.149664     Children        ...                   0.4722           0.9470   \n",
       "1  0.059930  Adolescents        ...                   0.3621           0.3730   \n",
       "2  0.056563  Adolescents        ...                   0.7979           0.4853   \n",
       "\n",
       "   VLPFC.R_DLPFCm.L  VLPFC.R_DLPFCm.R  DLPFC.L_DLPFC.R  DLPFC.L_DLPFCm.L  \\\n",
       "0            0.7317            1.2809           0.8010            0.0175   \n",
       "1            0.5669            0.5315           1.1184            1.1773   \n",
       "2            0.3248            0.6449           1.0761            0.0941   \n",
       "\n",
       "   DLPFC.L_DLPFCm.R  DLPFC.R_DLPFCm.L  DLPFC.R_DLPFCm.R  DLPFCm.L_DLPFCm.R  \n",
       "0            0.1136            0.2156            0.5137             1.2603  \n",
       "1            1.0380            1.1589            0.6858             1.2571  \n",
       "2            0.2069           -0.0811            0.1089             0.9859  \n",
       "\n",
       "[3 rows x 1236 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data check\n",
    "print(df.keys())\n",
    "print(df[str(emotion[0])].shape)\n",
    "df[str(emotion[0])].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 1236)\n"
     ]
    }
   ],
   "source": [
    "# combine four emotion data\n",
    "data = pd.concat([df[\"fear\"],df[\"anger\"],df[\"sad\"],df[\"happy\"]], axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with column mean\n",
    "def replace_nan(X):\n",
    "    col_mean = np.nanmean(X, axis=0) # obtain column means\n",
    "    ind = np.where(np.isnan(X)) # find the position of missing values\n",
    "    X[ind] = np.take(col_mean, ind[1]) # replace nans with colmeans\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3036, 1225)\ty shape: (3036,)\tG shape: (3036,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for emotion classification\n",
    "\n",
    "# Features\n",
    "X = data.drop(columns = sub.columns) # drop subID, age, group etc.\n",
    "#X.head(3)\n",
    "X = X.drop(columns = X.columns[0]) # drop subID\n",
    "#X.head(3)\n",
    "X = X.values # convert pandas dataframe to numpy array\n",
    "# print(X.shape)\n",
    "#print(type(X))\n",
    "X = replace_nan(X) # deal with missing values in numpy array\n",
    "\n",
    "# Labels\n",
    "y = np.array([1,2,3,4]) \n",
    "y = np.repeat(y, num_sub)\n",
    "\n",
    "# Groups\n",
    "# Group info that will be used to do train-test split\n",
    "# data belongs to the same subject should not be splited into different folds\n",
    "G = np.array(range(num_sub)) +1\n",
    "G = np.tile(G, 4).T\n",
    "#print(G[0,759:789])\n",
    "print('X shape: ' + str(X.shape) + '\\ty shape: ' + str(y.shape) + '\\tG shape: ' + str(G.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split for 10 fold cross validation; \n",
    "# samples that belong to the same subject will not be\n",
    "# split into different folds\n",
    "def get_cv(X, y, G):\n",
    "    cv = GroupShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 42)\n",
    "    nfold = cv.get_n_splits()\n",
    "    cv = cv.split(X, y, G)\n",
    "    \n",
    "    return cv, nfold\n",
    "\n",
    "# train_inds, test_inds = next(cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Example of subsetting numpy array\n",
    "a = np.arange(100).reshape(10,10)\n",
    "#print(a)\n",
    "n1, n2 = np.arange(5), np.arange(5)\n",
    "#print(n1.shape)\n",
    "b = a[n1[:,None],n2[None,:]]\n",
    "b\n",
    "\n",
    "n1 = np.concatenate((np.arange(100), np.arange(100)+759))\n",
    "n1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Test using glmnet\n",
    "import glmnet\n",
    "\n",
    "model = glmnet.logistic.LogitNet(alpha=0.2)\n",
    "\n",
    "inds = np.concatenate((np.arange(100), np.arange(100)+759, np.arange(100)+759*2, np.arange(100)+759*3))\n",
    "m = model.fit(X[inds,:],y[inds])\n",
    "\n",
    "m.predict(X[inds+100,:]) # this returns the predicted value at the best lambda\n",
    "np.sum(m.predict == y[inds+100])\n",
    "m.lambda_best_  # best lambda\n",
    "m.lambda_best_inx_  # the position of the best lambda\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data: which emotions are included, and which agebin are included\n",
    "emotion_classes = 24 #['fear', 'anger']\n",
    "age_range = 'FULL'\n",
    "sub_info = sub['Age']\n",
    "#print(sub_info)\n",
    "\n",
    "# re-organize data for classification\n",
    "def data_reorganize(emotion_classes, age_range, sub_info, X, y, G):\n",
    "    nsub = len(sub_info)\n",
    "    age = np.tile(sub_info, 4).T\n",
    "    #print(age.shape)\n",
    "\n",
    "    if emotion_classes == 1234:\n",
    "        return X, y, G\n",
    "    else:\n",
    "        if emotion_classes == 12: # fear and anger\n",
    "            inds = np.concatenate((np.arange(nsub), np.arange(nsub)+nsub))\n",
    "        elif emotion_classes == 13: # fear and sad\n",
    "            inds = np.concatenate((np.arange(nsub), np.arange(nsub)+nsub*2))\n",
    "        elif emotion_classes == 14: # fear and happy\n",
    "            inds = np.concatenate((np.arange(nsub), np.arange(nsub)+nsub*3))\n",
    "        elif emotion_classes == 23: # anger and sad\n",
    "            inds = np.concatenate((np.arange(nsub)+nsub, np.arange(nsub)+nsub*2))\n",
    "        elif emotion_classes == 24: # anger and happy\n",
    "            inds = np.concatenate((np.arange(nsub)+nsub, np.arange(nsub)+nsub*3))\n",
    "        elif emotion_classes == 34: # sad and happy\n",
    "            inds = np.concatenate((np.arange(nsub)+nsub*2, np.arange(nsub)+nsub*3))\n",
    "       \n",
    "        print(inds)\n",
    "\n",
    "        X_input = X[inds,:]\n",
    "        y_input = y[inds]\n",
    "        G_input = G[inds]\n",
    "        age_input = age[inds]\n",
    "\n",
    "        if age_range == 'FULL':\n",
    "            pass\n",
    "        else:\n",
    "            if age_range == 'CH':\n",
    "                aind = np.where(age_input < 13)[0]\n",
    "            elif age_range == 'ADO':\n",
    "                aind = np.where(np.logical_and(age_input >= 13, age_input < 18))[0]\n",
    "            elif age_range == 'ADU':\n",
    "                aind = np.where(age_input >= 18)[0]\n",
    "\n",
    "            X_input = X_input[aind,:]\n",
    "            y_input = y_input[aind]\n",
    "            G_input = G_input[aind]\n",
    "    \n",
    "        return X_input, y_input, G_input  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1515 1516 1517]\n",
      "(1518, 1225)\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "emotion_classes = 12\n",
    "age_range = 'FULL'\n",
    "subj_age = sub['Age']\n",
    "X_input, y_input, G_input = data_reorganize(emotion_classes, age_range, subj_age, X, y, G)\n",
    "\n",
    "print(X_input.shape)\n",
    "#print(y_input)\n",
    "#print(G_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1518 1519 1520 ... 3033 3034 3035]\n"
     ]
    }
   ],
   "source": [
    "# four emotion, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(1234, 'FULL', sub['Age'], X, y, G)\n",
    "# fear vs. anger, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(12, 'ADU', sub['Age'], X, y, G)\n",
    "# fear vs. sad, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(13, 'ADU', sub['Age'], X, y, G)\n",
    "# fear vs. happy, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(14, 'ADU', sub['Age'], X, y, G)\n",
    "# anger vs. sad, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(23, 'ADU', sub['Age'], X, y, G)\n",
    "# anger vs. happy, full age range\n",
    "#X_input, y_input, G_input = data_reorganize(24, 'ADU', sub['Age'], X, y, G)\n",
    "# sad vs. happy, full age range\n",
    "X_input, y_input, G_input = data_reorganize(34, 'ADU', sub['Age'], X, y, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of folds: 10\n",
      "alpha 0.1\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5895238095238096 at alpha: 0.1\n",
      "test accuracy 0.5528301886792453 at alpha: 0.1\n",
      "alpha 0.2\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.583452380952381 at alpha: 0.2\n",
      "test accuracy 0.5466981132075471 at alpha: 0.2\n",
      "alpha 0.30000000000000004\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5800793650793651 at alpha: 0.30000000000000004\n",
      "test accuracy 0.5449685534591195 at alpha: 0.30000000000000004\n",
      "alpha 0.4\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5827976190476191 at alpha: 0.4\n",
      "test accuracy 0.5457547169811321 at alpha: 0.4\n",
      "alpha 0.5\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.581 at alpha: 0.5\n",
      "test accuracy 0.5437735849056604 at alpha: 0.5\n",
      "alpha 0.6000000000000001\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5839285714285715 at alpha: 0.6000000000000001\n",
      "test accuracy 0.5449685534591195 at alpha: 0.6000000000000001\n",
      "alpha 0.7000000000000001\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5853741496598639 at alpha: 0.7000000000000001\n",
      "test accuracy 0.545822102425876 at alpha: 0.7000000000000001\n",
      "alpha 0.8\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5868154761904761 at alpha: 0.8\n",
      "test accuracy 0.5462264150943397 at alpha: 0.8\n",
      "alpha 0.9\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5888888888888889 at alpha: 0.9\n",
      "test accuracy 0.5474842767295598 at alpha: 0.9\n",
      "alpha 1.0\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "training accuracy: 0.5882142857142857 at alpha: 1.0\n",
      "test accuracy 0.5469811320754717 at alpha: 1.0\n"
     ]
    }
   ],
   "source": [
    "import glmnet\n",
    "\n",
    "alpha_range = (np.arange(10)+1)*0.1\n",
    "results = []\n",
    "\n",
    "cv_splits, nfold = get_cv(X_input, y_input, G_input)\n",
    "print(\"number of folds: \" + str(nfold))\n",
    "# get train and test indices for all folds\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "\n",
    "for train_inds, test_inds in cv_splits:\n",
    "    train_folds.append(train_inds)\n",
    "    test_folds.append(test_inds)\n",
    "\n",
    "\n",
    "    \n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    print(\"alpha \" + str(alpha))\n",
    "    \n",
    "    # nfold cross validation\n",
    "    for fd in range(nfold):\n",
    "    #for train_inds, test_inds in cv_splits:\n",
    "        print(\"fold \" + str(fd))\n",
    "        X_train, y_train, X_test, y_test = X_input[train_folds[fd],:], y_input[train_folds[fd]], X_input[test_folds[fd],:], y_input[test_folds[fd]]\n",
    "        \n",
    "        model = glmnet.logistic.LogitNet(alpha=alpha)\n",
    "        m = model.fit(X_train,y_train)\n",
    "        train_preds = np.concatenate((train_preds, m.predict(X_train) == y_train))\n",
    "        test_preds = np.concatenate((test_preds, m.predict(X_test) == y_test))\n",
    "        results.append((alpha, m.lambda_best_, train_preds, test_preds, m)) \n",
    "        #print(\"training accuracy: \" + str(np.mean(train_preds)) + \" at alpha: \" + str(alpha) + \" and lambda: \" + str(m.lambda_best_))\n",
    "        #print(\"test accuracy \" + str(np.mean(test_preds)) + \" at alpha: \" + str(alpha) + \" and lambda: \" + str(m.lambda_best_)) \n",
    "        fd += 1\n",
    "    \n",
    "    train_acc = np.mean(train_preds)\n",
    "    test_acc = np.mean(test_preds)\n",
    "    print(\"training accuracy: \" + str(train_acc) + \" at alpha: \" + str(alpha))\n",
    "    print(\"test accuracy \" + str(test_acc) + \" at alpha: \" + str(alpha))  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import glmnet\n",
    "# define my glmnet model (data normalization, glmnet)\n",
    "def myGLMNet(alpha):\n",
    "    pipe = Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"glmnet\", glmnet.logistic.LogitNet(alpha = alpha).fit())\n",
    "    ])\n",
    "\n",
    "# define evaluation\n",
    "def evaluation(X, y, G, alpha):\n",
    "    pipe = myGLMNet(alpha=alpha) \n",
    "    cv = get_cv(X, y, G)\n",
    "        \n",
    "    results = cross_validate(pipe, X, y, scoring=['accuracy'], cv=cv, verbose=1, return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "alpha_range = [0.1,0.5] #np.logspace(-7, 1, 9)\n",
    "models = []\n",
    "for alpha in alpha_range:\n",
    "        results = evaluation(X,y,G,alpha)\n",
    "        models.append((alpha,results))\n",
    "        print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),np.std(results['train_accuracy'])))\n",
    "        print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),np.std(results['test_accuracy'])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# define my SVC model (data normalization, SVC)\n",
    "def mySVC(gamma, C):\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", gamma=gamma, C=C))\n",
    "    ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mySVC(gamma=1, C=0.1)\n",
    "# model.fit(X_train,y_train)\n",
    "# model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def evaluation(X, y, G, gamma, C):\n",
    "    pipe = mySVC(gamma=gamma, C=C) \n",
    "    cv = get_cv(X, y, G)\n",
    "    #print(\"type(cv) = {}\".format(type(cv)))\n",
    "    \n",
    "    results = cross_validate(pipe, X, y, scoring=['accuracy'], cv=cv, verbose=1, return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    return results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = evaluation(X,y,G,gamma=1,C=0.1)\n",
    "#print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "#                                                         np.std(results['train_accuracy'])))\n",
    "#print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "#                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "C_range = np.exp2(np.array(range(-5,5))) #np.logspace(-3, 2, 6)\n",
    "gamma_range = np.exp2(np.array(range(-10,1)))\n",
    "models = []\n",
    "for C in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        results = evaluation(X,y,G,gamma,C)\n",
    "        models.append((C,gamma,results))\n",
    "        print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "        print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set the parameters\n",
    "#tuned_parameters = [{'kernal': ['rbf'], 'gamma':[np.exp2(np.array(range(-2,2)))], 'C': [np.exp2(np.array(range(-2,2)))]}]\n",
    "\n",
    "estimators = [(\"std_scaler\", StandardScaler()), (\"svc\", SVC())]\n",
    "tuned_parameters = [{'svc__gamma':[np.exp2(np.array(range(-2,2)))], 'svc__C': [np.exp2(np.array(range(-2,2)))]}]\n",
    "\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "#cv = get_cv(X, y, G)\n",
    "clf = GridSearchCV(pipe, param_grid = tuned_parameters, cv = 4, scoring='accuracy', n_jobs=-1)\n",
    "clf.fit(X,y)\n",
    "\n",
    "print('Best parameters set found: ')\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
